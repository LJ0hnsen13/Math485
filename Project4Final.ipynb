{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib as mpl\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary Data Fetching, Cleaning, and Vectorization. This code also initiates the sdg assignment to each sentence in the array - enabling us to sort and organize each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/luke/GitMath/\"\n",
    "sdg_names = pd.read_csv(data_dir + \"sdg_name_definition.csv\")\n",
    "text_file_name = \"osdg-community-data-v2024-04-01.csv\"\n",
    "text_df = pd.read_csv(data_dir + text_file_name,sep = \"\\t\",  quotechar='\"')\n",
    "text_df.drop(text_df.columns.values[0],axis = 1, inplace=True)\n",
    "text_df = text_df.query(\"agreement > 0.5 and (labels_positive - labels_negative) > 2\").reset_index(drop=True)\n",
    "corpus = text_df.text\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer.fit(corpus)\n",
    "count_vector = count_vectorizer.transform(corpus).toarray() \n",
    "count_vector_df = pd.DataFrame(count_vector, columns=count_vectorizer.get_feature_names_out())\n",
    "term_freq = pd.DataFrame({\"term\": count_vector_df.columns.values, \"freq\" : count_vector_df.sum(axis=0)})\n",
    "term_freq.sort_values(by=\"freq\", ascending=False)\n",
    "sdg_num = text_df.sdg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDG_CLASSIFIER takes in our data (corpus), what type of algorithm we want to use (classifier_algorithm), the vectorizer type (vectorizer_type), bigram or unigram (ngram_range), and the min_df value. It then splits the data into training and testing partitions, sorts based on the fed information, and then runs the selected classifier, returning the accuracy, recall, f1_score, and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_classifier(corpus, classifier_algorithm, vectorizer_type='count', ngram_range=(1,1), stop_words='english', min_df=2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(corpus, sdg_num, test_size=0.25, random_state=8)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    if vectorizer_type == 'count':\n",
    "        vectorizer = CountVectorizer(\n",
    "            ngram_range=ngram_range, \n",
    "            stop_words=stop_words,\n",
    "            min_df=min_df\n",
    "        )\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            ngram_range=ngram_range, \n",
    "            stop_words=stop_words,\n",
    "            min_df=min_df\n",
    "        )\n",
    "\n",
    "    X_train_vector = vectorizer.fit_transform(X_train)\n",
    "    X_test_vector = vectorizer.transform(X_test)\n",
    "\n",
    "    if isinstance(classifier_algorithm, str):\n",
    "        if classifier_algorithm.lower() == 'multinomialnb':\n",
    "            clf = MultinomialNB()\n",
    "        elif classifier_algorithm.lower() == 'mlp':\n",
    "            clf = MLPClassifier(max_iter=5, random_state=8)\n",
    "        elif classifier_algorithm.lower() == 'ridge':\n",
    "            clf = RidgeClassifier(alpha=1, solver='auto', max_iter=5)\n",
    "    else:\n",
    "        clf = classifier_algorithm\n",
    "    \n",
    "    clf.fit(X_train_vector, y_train)\n",
    "    y_pred = clf.predict(X_test_vector)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains all the configurations/combinations of vectorizer_type, ngram_range, and min_df we select. It then runs these selected configurations and appends the results into a table, printing a \"B: \" next to the best value in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconfigurations = [\\n    {\\'vectorizer\\': \\'count\\', \\'ngram_range\\': (1, 1), \\'min_df\\': 2},\\n    {\\'vectorizer\\': \\'count\\', \\'ngram_range\\': (2, 2), \\'min_df\\': 2},\\n    {\\'vectorizer\\': \\'count\\', \\'ngram_range\\': (1, 2), \\'min_df\\': 2},\\n    {\\'vectorizer\\': \\'tfidf\\', \\'ngram_range\\': (1, 1), \\'min_df\\': 2},\\n    {\\'vectorizer\\': \\'tfidf\\', \\'ngram_range\\': (2, 2), \\'min_df\\': 2},\\n    {\\'vectorizer\\': \\'tfidf\\', \\'ngram_range\\': (1, 2), \\'min_df\\': 2}\\n]\\n\\nresults = []\\n\\nfor config in configurations:\\n    vectorizer_type = config[\\'vectorizer\\']\\n    ngram_range = config[\\'ngram_range\\']\\n    min_df = config[\\'min_df\\']\\n    \\n    run1 = sdg_classifier(corpus, classifier_algorithm=\\'multinomialnb\\', \\n                           vectorizer_type=vectorizer_type, \\n                           ngram_range=ngram_range, min_df=min_df)\\n    \\n    run2 = sdg_classifier(corpus, classifier_algorithm=\\'mlp\\', \\n                           vectorizer_type=vectorizer_type, \\n                           ngram_range=ngram_range, min_df=min_df)\\n    \\n    run3 = sdg_classifier(corpus, classifier_algorithm=\\'ridge\\', \\n                           vectorizer_type=vectorizer_type, \\n                           ngram_range=ngram_range, min_df=min_df)\\n    \\n    results.append({\\n        \\'vectorizer\\': vectorizer_type,\\n        \\'ngram_range\\': str(ngram_range),\\n        \\'min_df\\': min_df,\\n        \\'MultinomialNB_precision\\': run1[\\'precision\\'],\\n        \\'MLP_precision\\': run2[\\'precision\\'],\\n        \\'Ridge_precision\\': run3[\\'precision\\'],\\n        \\'MultinomialNB_recall\\': run1[\\'recall\\'],\\n        \\'MLP_recall\\': run2[\\'recall\\'],\\n        \\'Ridge_recall\\': run3[\\'recall\\'],\\n        \\'MultinomialNB_f1\\': run1[\\'f1_score\\'],\\n        \\'MLP_f1\\': run2[\\'f1_score\\'],\\n        \\'Ridge_f1\\': run3[\\'f1_score\\'],\\n        \\'MultinomialNB_accuracy\\': run1[\\'accuracy\\'],\\n        \\'MLP_accuracy\\': run2[\\'accuracy\\'],\\n        \\'Ridge_accuracy\\': run3[\\'accuracy\\']\\n    })\\n\\nresults_df = pd.DataFrame(results)\\ndef highlight_best(s):\\n    return [\"B: \" + str(v) if v == s.max() else str(v) for v in s]\\n\\nhighlighted_df = results_df.copy()\\nmetrics = [\\'precision\\', \\'recall\\', \\'f1\\', \\'accuracy\\']\\nfor metric in metrics:\\n    highlighted_df[[f\\'MultinomialNB_{metric}\\', f\\'MLP_{metric}\\', f\\'Ridge_{metric}\\']] = highlighted_df[[f\\'MultinomialNB_{metric}\\', f\\'MLP_{metric}\\', f\\'Ridge_{metric}\\']].apply(highlight_best)\\n\\nhighlighted_df\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "configurations = [\n",
    "    {'vectorizer': 'count', 'ngram_range': (1, 1), 'min_df': 2},\n",
    "    {'vectorizer': 'count', 'ngram_range': (2, 2), 'min_df': 2},\n",
    "    {'vectorizer': 'count', 'ngram_range': (1, 2), 'min_df': 2},\n",
    "    {'vectorizer': 'tfidf', 'ngram_range': (1, 1), 'min_df': 2},\n",
    "    {'vectorizer': 'tfidf', 'ngram_range': (2, 2), 'min_df': 2},\n",
    "    {'vectorizer': 'tfidf', 'ngram_range': (1, 2), 'min_df': 2}\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configurations:\n",
    "    vectorizer_type = config['vectorizer']\n",
    "    ngram_range = config['ngram_range']\n",
    "    min_df = config['min_df']\n",
    "    \n",
    "    run1 = sdg_classifier(corpus, classifier_algorithm='multinomialnb', \n",
    "                           vectorizer_type=vectorizer_type, \n",
    "                           ngram_range=ngram_range, min_df=min_df)\n",
    "    \n",
    "    run2 = sdg_classifier(corpus, classifier_algorithm='mlp', \n",
    "                           vectorizer_type=vectorizer_type, \n",
    "                           ngram_range=ngram_range, min_df=min_df)\n",
    "    \n",
    "    run3 = sdg_classifier(corpus, classifier_algorithm='ridge', \n",
    "                           vectorizer_type=vectorizer_type, \n",
    "                           ngram_range=ngram_range, min_df=min_df)\n",
    "    \n",
    "    results.append({\n",
    "        'vectorizer': vectorizer_type,\n",
    "        'ngram_range': str(ngram_range),\n",
    "        'min_df': min_df,\n",
    "        'MultinomialNB_precision': run1['precision'],\n",
    "        'MLP_precision': run2['precision'],\n",
    "        'Ridge_precision': run3['precision'],\n",
    "        'MultinomialNB_recall': run1['recall'],\n",
    "        'MLP_recall': run2['recall'],\n",
    "        'Ridge_recall': run3['recall'],\n",
    "        'MultinomialNB_f1': run1['f1_score'],\n",
    "        'MLP_f1': run2['f1_score'],\n",
    "        'Ridge_f1': run3['f1_score'],\n",
    "        'MultinomialNB_accuracy': run1['accuracy'],\n",
    "        'MLP_accuracy': run2['accuracy'],\n",
    "        'Ridge_accuracy': run3['accuracy']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "def highlight_best(s):\n",
    "    return [\"B: \" + str(v) if v == s.max() else str(v) for v in s]\n",
    "\n",
    "highlighted_df = results_df.copy()\n",
    "metrics = ['precision', 'recall', 'f1', 'accuracy']\n",
    "for metric in metrics:\n",
    "    highlighted_df[[f'MultinomialNB_{metric}', f'MLP_{metric}', f'Ridge_{metric}']] = highlighted_df[[f'MultinomialNB_{metric}', f'MLP_{metric}', f'Ridge_{metric}']].apply(highlight_best)\n",
    "\n",
    "highlighted_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided Links  \n",
    "With min_df = 3\n",
    "\n",
    "| Bigram with Count Vectors     | MultinomialNB | MLP  | Ridge |\n",
    "|:------------------------------|:--------------|:-----|:------|\n",
    "| Precision                     | .814          | **.824** | .792  |\n",
    "| Recall                        | .810          | **.822** | .794  |\n",
    "| F1                            | .804          | **.819** | .791  |\n",
    "| Accuracy                      | .810          | **.822** | .794  |\n",
    "| Unigram with Count Vectors    |               |      |       |\n",
    "| Precision                     | .849          | **.878** | .811  |\n",
    "| Recall                        | .848          | **.878** | .810  |\n",
    "| F1                            | .846          | **.879** | .810  |\n",
    "| Accuracy                      | .848          | **.878** | .810  |\n",
    "| Mixed Gram with Count Vectors |               |      |       |\n",
    "| Precision                     | .841          | **.891** | .874  |\n",
    "| Recall                        | .830          | **.891** | .875  |\n",
    "| F1                            | .820          | **.890** | .873  |\n",
    "| Accuracy                      | .830          | **.891** | .875  |\n",
    "| Bigram with tfidf Vectors     |               |      |       |\n",
    "| Precision                     | .780          | **.830** | .821  |\n",
    "| Recall                        | .695          | **.830** | .821  |\n",
    "| F1                            | .665          | **.827** | .818  |\n",
    "| Accuracy                      | .695          | **.830** | .822  |\n",
    "| Unigram with tfidf Vectors    |               |      |       |\n",
    "| Precision                     | .811          | **.882** | .880  |\n",
    "| Recall                        | .745          | **.882** | **.882**  |\n",
    "| F1                            | .723          | **.881** | .880  |\n",
    "| Accuracy                      | .745          | **.882** | **.882**  |\n",
    "| Mixed Gram with tfidf Vectors |               |      |       |\n",
    "| Precision                     | .801          | **.890** | .889  |\n",
    "| Recall                        | .700          | **.891** | .889  |\n",
    "| F1                            | .671          | **.890** | .887  |\n",
    "| Accuracy                      | .700          | **.891** | .889  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigram with Count Vectors (MultinomialNB):**\n",
    "This model achieves a precision of 0.814 and recall of 0.810, leading to an F1 score of 0.804. The accuracy is 0.810, indicating a strong balance between precision and recall for this setup.\n",
    "\n",
    "**Unigram with Count Vectors (MultinomialNB):**\n",
    "With a precision of 0.849, recall of 0.848, and F1 score of 0.846, this model slightly outperforms the bigram setup. The accuracy is also higher at 0.848, making it a more reliable approach for classification.\n",
    "\n",
    "**Mixed Gram with Count Vectors (MultinomialNB):**\n",
    "This model performs comparably to the unigram approach, with precision at 0.841, recall at 0.830, and an F1 score of 0.820. Accuracy is 0.830, showing strong performance but slightly lower than the unigram model.\n",
    "\n",
    "**Bigram with TF-IDF Vectors (MultinomialNB):**\n",
    "This approach struggles in comparison, achieving a precision of 0.780 and recall of 0.695, resulting in an F1 score of 0.665. The accuracy is also lower at 0.695, suggesting limited effectiveness in distinguishing between classes.\n",
    "\n",
    "**Unigram with TF-IDF Vectors (MultinomialNB):**\n",
    "The model achieves a precision of 0.811, recall of 0.745, and an F1 score of 0.723. The accuracy is 0.745, indicating modest improvements over the bigram setup with TF-IDF vectors but still underperforming compared to the count vector approaches.\n",
    "\n",
    "**Mixed Gram with TF-IDF Vectors (MultinomialNB):**\n",
    "This model offers a slight improvement over the bigram and unigram TF-IDF setups, with a precision of 0.801, recall of 0.700, and an F1 score of 0.671. The accuracy is 0.700, reflecting moderate classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following code extracts the text from each url in the urls list. Then it breaks down the text line by line, creating the data array **corpus2_df** with a list called **corpus2** in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_full_text_from_url(url):\n",
    "    try:\n",
    "        # Send a GET request to the website\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract text from paragraphs, preserving the full context\n",
    "        paragraphs = [p.get_text(strip=True) for p in soup.find_all('p') if p and p.get_text(strip=True)]\n",
    "        \n",
    "        # Join paragraphs into a single full text string\n",
    "        full_text = ' '.join(paragraphs)\n",
    "        \n",
    "        return full_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {url}: {e}\")\n",
    "        return None\n",
    "urls = [\n",
    "    \"http://gianttortoise.org/en/beyond-tracking\",\n",
    "    \"https://www.dhs.gov/blue-campaign/what-human-trafficking\",\n",
    "    \"https://www.dol.gov/agencies/odep/program-areas/individuals/older-workers\",\n",
    "    \"https://michigantoday.umich.edu/2022/08/26/positively-breaking-the-age-code/\"\n",
    "]\n",
    "\n",
    "# Extract full text from all URLs\n",
    "all_texts = []\n",
    "for url in urls:\n",
    "    text = extract_full_text_from_url(url)\n",
    "    if text:\n",
    "        all_texts.append(text)\n",
    "\n",
    "# Create DataFrame\n",
    "corpus2_df = pd.DataFrame({'text': all_texts})\n",
    "corpus2 = corpus2_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Having discovered some of the mechanisms gover...\n",
       "1    An official website of the United States gover...\n",
       "2    An official website of the United States gover...\n",
       "3    Office of the VP for Communications â€“ Keeping ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this extracted text (now seperated into lines by sentence) and pass it into a function to label each line according to the SDG labels supplied by the UN. Each classifier algorithm may come up with different labels despite being trained on the previous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_classifier2(train_corpus, corpus2, train_label, classifier_algorithm='multinomialnb', vectorizer_type='count', ngram_range=(1,1), min_df=3):    \n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(train_label)\n",
    "    \n",
    "    if vectorizer_type == 'count':\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words='english', min_df=min_df)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, stop_words='english', min_df=min_df)\n",
    "\n",
    "    X_train_vector = vectorizer.fit_transform(train_corpus)\n",
    "    X_corpus2_vector = vectorizer.transform(corpus2)\n",
    "\n",
    "    if classifier_algorithm == 'multinomialnb':\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier_algorithm == 'mlp':\n",
    "        clf = MLPClassifier(max_iter=5, random_state=8)\n",
    "    elif classifier_algorithm == 'ridge':\n",
    "        clf = RidgeClassifier(alpha=1, solver='auto', max_iter=5)\n",
    "    else:\n",
    "        clf = classifier_algorithm\n",
    "    \n",
    "    clf.fit(X_train_vector, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_corpus2_vector)\n",
    "    \n",
    "    predicted_labels = le.inverse_transform(y_pred)\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG 1:\n",
      "  poverty: 0.0245\n",
      "  income: 0.0100\n",
      "  poor: 0.0075\n",
      "  countries: 0.0075\n",
      "  children: 0.0072\n",
      "  social: 0.0065\n",
      "  child: 0.0047\n",
      "  households: 0.0046\n",
      "  household: 0.0037\n",
      "  deprivation: 0.0035\n",
      "SDG 2:\n",
      "  food: 0.0147\n",
      "  agricultural: 0.0071\n",
      "  production: 0.0054\n",
      "  countries: 0.0049\n",
      "  prices: 0.0038\n",
      "  agriculture: 0.0034\n",
      "  price: 0.0033\n",
      "  farmers: 0.0030\n",
      "  land: 0.0028\n",
      "  security: 0.0027\n",
      "SDG 3:\n",
      "  health: 0.0245\n",
      "  care: 0.0167\n",
      "  services: 0.0061\n",
      "  countries: 0.0057\n",
      "  mental: 0.0040\n",
      "  oecd: 0.0038\n",
      "  primary: 0.0038\n",
      "  quality: 0.0038\n",
      "  patients: 0.0034\n",
      "  population: 0.0033\n",
      "SDG 4:\n",
      "  education: 0.0188\n",
      "  school: 0.0124\n",
      "  students: 0.0117\n",
      "  schools: 0.0088\n",
      "  teachers: 0.0081\n",
      "  learning: 0.0060\n",
      "  oecd: 0.0058\n",
      "  countries: 0.0054\n",
      "  skills: 0.0047\n",
      "  teacher: 0.0042\n",
      "SDG 5:\n",
      "  women: 0.0296\n",
      "  gender: 0.0157\n",
      "  men: 0.0069\n",
      "  countries: 0.0061\n",
      "  work: 0.0052\n",
      "  equality: 0.0045\n",
      "  social: 0.0042\n",
      "  rights: 0.0039\n",
      "  female: 0.0037\n",
      "  labour: 0.0036\n",
      "SDG 6:\n",
      "  water: 0.0390\n",
      "  management: 0.0051\n",
      "  groundwater: 0.0040\n",
      "  use: 0.0039\n",
      "  river: 0.0038\n",
      "  resources: 0.0038\n",
      "  quality: 0.0034\n",
      "  countries: 0.0032\n",
      "  supply: 0.0031\n",
      "  basin: 0.0031\n",
      "SDG 7:\n",
      "  energy: 0.0248\n",
      "  electricity: 0.0081\n",
      "  power: 0.0064\n",
      "  renewable: 0.0048\n",
      "  countries: 0.0045\n",
      "  efficiency: 0.0043\n",
      "  costs: 0.0042\n",
      "  capacity: 0.0036\n",
      "  technologies: 0.0034\n",
      "  cost: 0.0033\n",
      "SDG 8:\n",
      "  employment: 0.0076\n",
      "  labour: 0.0071\n",
      "  workers: 0.0058\n",
      "  work: 0.0049\n",
      "  countries: 0.0042\n",
      "  job: 0.0033\n",
      "  unemployment: 0.0033\n",
      "  market: 0.0032\n",
      "  sector: 0.0029\n",
      "  growth: 0.0028\n",
      "SDG 9:\n",
      "  development: 0.0068\n",
      "  countries: 0.0062\n",
      "  innovation: 0.0059\n",
      "  infrastructure: 0.0058\n",
      "  new: 0.0044\n",
      "  services: 0.0041\n",
      "  technology: 0.0041\n",
      "  access: 0.0037\n",
      "  data: 0.0036\n",
      "  policy: 0.0033\n",
      "SDG 10:\n",
      "  income: 0.0141\n",
      "  inequality: 0.0108\n",
      "  countries: 0.0089\n",
      "  social: 0.0057\n",
      "  tax: 0.0041\n",
      "  labour: 0.0040\n",
      "  oecd: 0.0040\n",
      "  growth: 0.0037\n",
      "  distribution: 0.0036\n",
      "  workers: 0.0033\n",
      "SDG 11:\n",
      "  urban: 0.0097\n",
      "  development: 0.0068\n",
      "  transport: 0.0066\n",
      "  public: 0.0059\n",
      "  cities: 0.0056\n",
      "  city: 0.0055\n",
      "  land: 0.0043\n",
      "  local: 0.0040\n",
      "  housing: 0.0040\n",
      "  use: 0.0038\n",
      "SDG 12:\n",
      "  waste: 0.0166\n",
      "  management: 0.0040\n",
      "  environmental: 0.0039\n",
      "  countries: 0.0036\n",
      "  recycling: 0.0030\n",
      "  production: 0.0027\n",
      "  consumption: 0.0027\n",
      "  collection: 0.0026\n",
      "  development: 0.0025\n",
      "  use: 0.0024\n",
      "SDG 13:\n",
      "  climate: 0.0223\n",
      "  change: 0.0090\n",
      "  finance: 0.0084\n",
      "  adaptation: 0.0083\n",
      "  countries: 0.0080\n",
      "  development: 0.0076\n",
      "  national: 0.0042\n",
      "  information: 0.0041\n",
      "  global: 0.0031\n",
      "  emissions: 0.0030\n",
      "SDG 14:\n",
      "  fisheries: 0.0096\n",
      "  fish: 0.0065\n",
      "  fishing: 0.0061\n",
      "  management: 0.0055\n",
      "  marine: 0.0046\n",
      "  aquaculture: 0.0038\n",
      "  species: 0.0033\n",
      "  ocean: 0.0030\n",
      "  production: 0.0030\n",
      "  sea: 0.0027\n",
      "SDG 15:\n",
      "  forest: 0.0115\n",
      "  biodiversity: 0.0103\n",
      "  forests: 0.0066\n",
      "  areas: 0.0064\n",
      "  species: 0.0057\n",
      "  national: 0.0050\n",
      "  management: 0.0046\n",
      "  land: 0.0045\n",
      "  protected: 0.0040\n",
      "  use: 0.0038\n",
      "SDG 16:\n",
      "  law: 0.0143\n",
      "  rights: 0.0119\n",
      "  international: 0.0108\n",
      "  human: 0.0085\n",
      "  article: 0.0064\n",
      "  public: 0.0057\n",
      "  social: 0.0052\n",
      "  political: 0.0051\n",
      "  legal: 0.0042\n",
      "  policy: 0.0040\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#for each SDG, what are the most differentiating features according to the classifier?\n",
    "\n",
    "def get_top_features_per_sdg(clf, corpus, sdg_labels, vectorizer_type='count', n_top_features=10):\n",
    "    if vectorizer_type == 'count':\n",
    "        vectorizer = CountVectorizer(stop_words='english', min_df=2)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', min_df=2)\n",
    "    X_vector = vectorizer.fit_transform(corpus)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    encoded_labels = le.fit_transform(sdg_labels)\n",
    "    \n",
    "    # Get unique labels in the order they were encoded\n",
    "    unique_labels = le.classes_\n",
    "    \n",
    "    # For MultinomialNB, log probabilities represent feature importance\n",
    "    feature_log_prob = clf.feature_log_prob_\n",
    "    \n",
    "    top_features = {}\n",
    "    for i, sdg in enumerate(unique_labels):\n",
    "        # Ensure we don't exceed the number of log probability rows\n",
    "        if i < feature_log_prob.shape[0]:\n",
    "            \n",
    "            # Convert log probabilities to probabilities using exponential\n",
    "            feature_probs = np.exp(feature_log_prob[i])\n",
    "            \n",
    "            # Get indices of top features for this SDG\n",
    "            top_feature_indices = feature_probs.argsort()[-n_top_features:][::-1]\n",
    "            \n",
    "            # Get the actual feature names and their probabilities\n",
    "            top_features[sdg] = [\n",
    "                (feature_names[idx], feature_probs[idx]) \n",
    "                for idx in top_feature_indices\n",
    "            ]\n",
    "    \n",
    "    return top_features\n",
    "\n",
    "# Usage remains the same\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=2)\n",
    "X_vector = vectorizer.fit_transform(corpus)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_vector, sdg_num)\n",
    "top_features = get_top_features_per_sdg(clf, corpus, sdg_num, vectorizer_type='count', n_top_features=10)\n",
    "\n",
    "# Print the results\n",
    "for sdg, features in top_features.items():\n",
    "    print(f\"SDG {sdg}:\")\n",
    "    for feature, prob in features:\n",
    "        print(f\"  {feature}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap Percentages:\n",
      "SDG 1:\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 11.11%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 17.65%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 5.26%\n",
      "SDG 2:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 5.26%\n",
      "  With SDG 12: 11.11%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 5.26%\n",
      "  With SDG 15: 5.26%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 3:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 4: 11.11%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 11.11%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 11.11%\n",
      "  With SDG 10: 11.11%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 4:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 11.11%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 11.11%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 5:\n",
      "  With SDG 1: 11.11%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 17.65%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 17.65%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 11.11%\n",
      "SDG 6:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 11.11%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 5.26%\n",
      "  With SDG 12: 17.65%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 5.26%\n",
      "  With SDG 15: 11.11%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 7:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 8:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 17.65%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 25.0%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 9:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 11.11%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 5.26%\n",
      "  With SDG 12: 11.11%\n",
      "  With SDG 13: 11.11%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 5.26%\n",
      "SDG 10:\n",
      "  With SDG 1: 17.65%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 11.11%\n",
      "  With SDG 4: 11.11%\n",
      "  With SDG 5: 17.65%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 25.0%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 5.26%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "  With SDG 16: 5.26%\n",
      "SDG 11:\n",
      "  With SDG 1: 0.0%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 0.0%\n",
      "  With SDG 4: 0.0%\n",
      "  With SDG 5: 0.0%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 0.0%\n",
      "  With SDG 8: 0.0%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 0.0%\n",
      "  With SDG 12: 11.11%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 11.11%\n",
      "  With SDG 16: 5.26%\n",
      "SDG 12:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 11.11%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 17.65%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 11.11%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 11.11%\n",
      "  With SDG 13: 11.11%\n",
      "  With SDG 14: 11.11%\n",
      "  With SDG 15: 11.11%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 13:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 5.26%\n",
      "  With SDG 4: 5.26%\n",
      "  With SDG 5: 5.26%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 5.26%\n",
      "  With SDG 8: 5.26%\n",
      "  With SDG 9: 11.11%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 5.26%\n",
      "  With SDG 12: 11.11%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 5.26%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 14:\n",
      "  With SDG 1: 0.0%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 0.0%\n",
      "  With SDG 4: 0.0%\n",
      "  With SDG 5: 0.0%\n",
      "  With SDG 6: 5.26%\n",
      "  With SDG 7: 0.0%\n",
      "  With SDG 8: 0.0%\n",
      "  With SDG 9: 0.0%\n",
      "  With SDG 10: 0.0%\n",
      "  With SDG 11: 0.0%\n",
      "  With SDG 12: 11.11%\n",
      "  With SDG 13: 0.0%\n",
      "  With SDG 15: 11.11%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 15:\n",
      "  With SDG 1: 0.0%\n",
      "  With SDG 2: 5.26%\n",
      "  With SDG 3: 0.0%\n",
      "  With SDG 4: 0.0%\n",
      "  With SDG 5: 0.0%\n",
      "  With SDG 6: 11.11%\n",
      "  With SDG 7: 0.0%\n",
      "  With SDG 8: 0.0%\n",
      "  With SDG 9: 0.0%\n",
      "  With SDG 10: 0.0%\n",
      "  With SDG 11: 11.11%\n",
      "  With SDG 12: 11.11%\n",
      "  With SDG 13: 5.26%\n",
      "  With SDG 14: 11.11%\n",
      "  With SDG 16: 0.0%\n",
      "SDG 16:\n",
      "  With SDG 1: 5.26%\n",
      "  With SDG 2: 0.0%\n",
      "  With SDG 3: 0.0%\n",
      "  With SDG 4: 0.0%\n",
      "  With SDG 5: 11.11%\n",
      "  With SDG 6: 0.0%\n",
      "  With SDG 7: 0.0%\n",
      "  With SDG 8: 0.0%\n",
      "  With SDG 9: 5.26%\n",
      "  With SDG 10: 5.26%\n",
      "  With SDG 11: 5.26%\n",
      "  With SDG 12: 0.0%\n",
      "  With SDG 13: 0.0%\n",
      "  With SDG 14: 0.0%\n",
      "  With SDG 15: 0.0%\n",
      "\n",
      "Detailed Overlapping Features:\n",
      "SDG 1 and SDG 2 share: ['countries']\n",
      "SDG 1 and SDG 3 share: ['countries']\n",
      "SDG 1 and SDG 4 share: ['countries']\n",
      "SDG 1 and SDG 5 share: ['social', 'countries']\n",
      "SDG 1 and SDG 6 share: ['countries']\n",
      "SDG 1 and SDG 7 share: ['countries']\n",
      "SDG 1 and SDG 8 share: ['countries']\n",
      "SDG 1 and SDG 9 share: ['countries']\n",
      "SDG 1 and SDG 10 share: ['social', 'countries', 'income']\n",
      "SDG 1 and SDG 12 share: ['countries']\n",
      "SDG 1 and SDG 13 share: ['countries']\n",
      "SDG 1 and SDG 16 share: ['social']\n",
      "SDG 2 and SDG 1 share: ['countries']\n",
      "SDG 2 and SDG 3 share: ['countries']\n",
      "SDG 2 and SDG 4 share: ['countries']\n",
      "SDG 2 and SDG 5 share: ['countries']\n",
      "SDG 2 and SDG 6 share: ['countries']\n",
      "SDG 2 and SDG 7 share: ['countries']\n",
      "SDG 2 and SDG 8 share: ['countries']\n",
      "SDG 2 and SDG 9 share: ['countries']\n",
      "SDG 2 and SDG 10 share: ['countries']\n",
      "SDG 2 and SDG 11 share: ['land']\n",
      "SDG 2 and SDG 12 share: ['production', 'countries']\n",
      "SDG 2 and SDG 13 share: ['countries']\n",
      "SDG 2 and SDG 14 share: ['production']\n",
      "SDG 2 and SDG 15 share: ['land']\n",
      "SDG 3 and SDG 1 share: ['countries']\n",
      "SDG 3 and SDG 2 share: ['countries']\n",
      "SDG 3 and SDG 4 share: ['countries', 'oecd']\n",
      "SDG 3 and SDG 5 share: ['countries']\n",
      "SDG 3 and SDG 6 share: ['countries', 'quality']\n",
      "SDG 3 and SDG 7 share: ['countries']\n",
      "SDG 3 and SDG 8 share: ['countries']\n",
      "SDG 3 and SDG 9 share: ['services', 'countries']\n",
      "SDG 3 and SDG 10 share: ['countries', 'oecd']\n",
      "SDG 3 and SDG 12 share: ['countries']\n",
      "SDG 3 and SDG 13 share: ['countries']\n",
      "SDG 4 and SDG 1 share: ['countries']\n",
      "SDG 4 and SDG 2 share: ['countries']\n",
      "SDG 4 and SDG 3 share: ['countries', 'oecd']\n",
      "SDG 4 and SDG 5 share: ['countries']\n",
      "SDG 4 and SDG 6 share: ['countries']\n",
      "SDG 4 and SDG 7 share: ['countries']\n",
      "SDG 4 and SDG 8 share: ['countries']\n",
      "SDG 4 and SDG 9 share: ['countries']\n",
      "SDG 4 and SDG 10 share: ['countries', 'oecd']\n",
      "SDG 4 and SDG 12 share: ['countries']\n",
      "SDG 4 and SDG 13 share: ['countries']\n",
      "SDG 5 and SDG 1 share: ['social', 'countries']\n",
      "SDG 5 and SDG 2 share: ['countries']\n",
      "SDG 5 and SDG 3 share: ['countries']\n",
      "SDG 5 and SDG 4 share: ['countries']\n",
      "SDG 5 and SDG 6 share: ['countries']\n",
      "SDG 5 and SDG 7 share: ['countries']\n",
      "SDG 5 and SDG 8 share: ['work', 'countries', 'labour']\n",
      "SDG 5 and SDG 9 share: ['countries']\n",
      "SDG 5 and SDG 10 share: ['social', 'countries', 'labour']\n",
      "SDG 5 and SDG 12 share: ['countries']\n",
      "SDG 5 and SDG 13 share: ['countries']\n",
      "SDG 5 and SDG 16 share: ['social', 'rights']\n",
      "SDG 6 and SDG 1 share: ['countries']\n",
      "SDG 6 and SDG 2 share: ['countries']\n",
      "SDG 6 and SDG 3 share: ['countries', 'quality']\n",
      "SDG 6 and SDG 4 share: ['countries']\n",
      "SDG 6 and SDG 5 share: ['countries']\n",
      "SDG 6 and SDG 7 share: ['countries']\n",
      "SDG 6 and SDG 8 share: ['countries']\n",
      "SDG 6 and SDG 9 share: ['countries']\n",
      "SDG 6 and SDG 10 share: ['countries']\n",
      "SDG 6 and SDG 11 share: ['use']\n",
      "SDG 6 and SDG 12 share: ['countries', 'management', 'use']\n",
      "SDG 6 and SDG 13 share: ['countries']\n",
      "SDG 6 and SDG 14 share: ['management']\n",
      "SDG 6 and SDG 15 share: ['management', 'use']\n",
      "SDG 7 and SDG 1 share: ['countries']\n",
      "SDG 7 and SDG 2 share: ['countries']\n",
      "SDG 7 and SDG 3 share: ['countries']\n",
      "SDG 7 and SDG 4 share: ['countries']\n",
      "SDG 7 and SDG 5 share: ['countries']\n",
      "SDG 7 and SDG 6 share: ['countries']\n",
      "SDG 7 and SDG 8 share: ['countries']\n",
      "SDG 7 and SDG 9 share: ['countries']\n",
      "SDG 7 and SDG 10 share: ['countries']\n",
      "SDG 7 and SDG 12 share: ['countries']\n",
      "SDG 7 and SDG 13 share: ['countries']\n",
      "SDG 8 and SDG 1 share: ['countries']\n",
      "SDG 8 and SDG 2 share: ['countries']\n",
      "SDG 8 and SDG 3 share: ['countries']\n",
      "SDG 8 and SDG 4 share: ['countries']\n",
      "SDG 8 and SDG 5 share: ['work', 'countries', 'labour']\n",
      "SDG 8 and SDG 6 share: ['countries']\n",
      "SDG 8 and SDG 7 share: ['countries']\n",
      "SDG 8 and SDG 9 share: ['countries']\n",
      "SDG 8 and SDG 10 share: ['workers', 'countries', 'growth', 'labour']\n",
      "SDG 8 and SDG 12 share: ['countries']\n",
      "SDG 8 and SDG 13 share: ['countries']\n",
      "SDG 9 and SDG 1 share: ['countries']\n",
      "SDG 9 and SDG 2 share: ['countries']\n",
      "SDG 9 and SDG 3 share: ['services', 'countries']\n",
      "SDG 9 and SDG 4 share: ['countries']\n",
      "SDG 9 and SDG 5 share: ['countries']\n",
      "SDG 9 and SDG 6 share: ['countries']\n",
      "SDG 9 and SDG 7 share: ['countries']\n",
      "SDG 9 and SDG 8 share: ['countries']\n",
      "SDG 9 and SDG 10 share: ['countries']\n",
      "SDG 9 and SDG 11 share: ['development']\n",
      "SDG 9 and SDG 12 share: ['countries', 'development']\n",
      "SDG 9 and SDG 13 share: ['countries', 'development']\n",
      "SDG 9 and SDG 16 share: ['policy']\n",
      "SDG 10 and SDG 1 share: ['social', 'countries', 'income']\n",
      "SDG 10 and SDG 2 share: ['countries']\n",
      "SDG 10 and SDG 3 share: ['countries', 'oecd']\n",
      "SDG 10 and SDG 4 share: ['countries', 'oecd']\n",
      "SDG 10 and SDG 5 share: ['social', 'countries', 'labour']\n",
      "SDG 10 and SDG 6 share: ['countries']\n",
      "SDG 10 and SDG 7 share: ['countries']\n",
      "SDG 10 and SDG 8 share: ['workers', 'countries', 'growth', 'labour']\n",
      "SDG 10 and SDG 9 share: ['countries']\n",
      "SDG 10 and SDG 12 share: ['countries']\n",
      "SDG 10 and SDG 13 share: ['countries']\n",
      "SDG 10 and SDG 16 share: ['social']\n",
      "SDG 11 and SDG 2 share: ['land']\n",
      "SDG 11 and SDG 6 share: ['use']\n",
      "SDG 11 and SDG 9 share: ['development']\n",
      "SDG 11 and SDG 12 share: ['use', 'development']\n",
      "SDG 11 and SDG 13 share: ['development']\n",
      "SDG 11 and SDG 15 share: ['land', 'use']\n",
      "SDG 11 and SDG 16 share: ['public']\n",
      "SDG 12 and SDG 1 share: ['countries']\n",
      "SDG 12 and SDG 2 share: ['production', 'countries']\n",
      "SDG 12 and SDG 3 share: ['countries']\n",
      "SDG 12 and SDG 4 share: ['countries']\n",
      "SDG 12 and SDG 5 share: ['countries']\n",
      "SDG 12 and SDG 6 share: ['countries', 'management', 'use']\n",
      "SDG 12 and SDG 7 share: ['countries']\n",
      "SDG 12 and SDG 8 share: ['countries']\n",
      "SDG 12 and SDG 9 share: ['countries', 'development']\n",
      "SDG 12 and SDG 10 share: ['countries']\n",
      "SDG 12 and SDG 11 share: ['use', 'development']\n",
      "SDG 12 and SDG 13 share: ['countries', 'development']\n",
      "SDG 12 and SDG 14 share: ['production', 'management']\n",
      "SDG 12 and SDG 15 share: ['management', 'use']\n",
      "SDG 13 and SDG 1 share: ['countries']\n",
      "SDG 13 and SDG 2 share: ['countries']\n",
      "SDG 13 and SDG 3 share: ['countries']\n",
      "SDG 13 and SDG 4 share: ['countries']\n",
      "SDG 13 and SDG 5 share: ['countries']\n",
      "SDG 13 and SDG 6 share: ['countries']\n",
      "SDG 13 and SDG 7 share: ['countries']\n",
      "SDG 13 and SDG 8 share: ['countries']\n",
      "SDG 13 and SDG 9 share: ['countries', 'development']\n",
      "SDG 13 and SDG 10 share: ['countries']\n",
      "SDG 13 and SDG 11 share: ['development']\n",
      "SDG 13 and SDG 12 share: ['countries', 'development']\n",
      "SDG 13 and SDG 15 share: ['national']\n",
      "SDG 14 and SDG 2 share: ['production']\n",
      "SDG 14 and SDG 6 share: ['management']\n",
      "SDG 14 and SDG 12 share: ['production', 'management']\n",
      "SDG 14 and SDG 15 share: ['species', 'management']\n",
      "SDG 15 and SDG 2 share: ['land']\n",
      "SDG 15 and SDG 6 share: ['management', 'use']\n",
      "SDG 15 and SDG 11 share: ['land', 'use']\n",
      "SDG 15 and SDG 12 share: ['management', 'use']\n",
      "SDG 15 and SDG 13 share: ['national']\n",
      "SDG 15 and SDG 14 share: ['species', 'management']\n",
      "SDG 16 and SDG 1 share: ['social']\n",
      "SDG 16 and SDG 5 share: ['social', 'rights']\n",
      "SDG 16 and SDG 9 share: ['policy']\n",
      "SDG 16 and SDG 10 share: ['social']\n",
      "SDG 16 and SDG 11 share: ['public']\n"
     ]
    }
   ],
   "source": [
    "#are there any overlaps between the SDG vocabularies?\n",
    "\n",
    "def analyze_vocabulary_overlap(top_features, detailed=True):\n",
    "    # Create sets of top features for each SDG\n",
    "    feature_sets = {sdg: set(feature for feature, _ in features) \n",
    "                    for sdg, features in top_features.items()}\n",
    "    \n",
    "    # Compute pairwise intersections\n",
    "    overlap_matrix = {}\n",
    "    detailed_overlap = {}\n",
    "    \n",
    "    for sdg1 in feature_sets:\n",
    "        overlap_matrix[sdg1] = {}\n",
    "        detailed_overlap[sdg1] = {}\n",
    "        \n",
    "        for sdg2 in feature_sets:\n",
    "            intersection = feature_sets[sdg1].intersection(feature_sets[sdg2])\n",
    "            overlap_count = len(intersection)\n",
    "            total_unique = len(feature_sets[sdg1].union(feature_sets[sdg2]))\n",
    "            overlap_percentage = (overlap_count / total_unique) * 100 if total_unique > 0 else 0\n",
    "            overlap_matrix[sdg1][sdg2] = round(overlap_percentage, 2)\n",
    "            \n",
    "            # If detailed mode is on, store the actual overlapping features\n",
    "            if detailed and sdg1 != sdg2:\n",
    "                detailed_overlap[sdg1][sdg2] = list(intersection)\n",
    "    \n",
    "    # Return percentage overlap matrix and features\n",
    "    return {\n",
    "        'overlap_percentages': overlap_matrix,\n",
    "        'overlapping_features': detailed_overlap\n",
    "    }\n",
    "overlap = analyze_vocabulary_overlap(top_features)\n",
    "\n",
    "# Print overlap percentages\n",
    "print(\"Overlap Percentages:\")\n",
    "for sdg1, overlaps in overlap['overlap_percentages'].items():\n",
    "    print(f\"SDG {sdg1}:\")\n",
    "    for sdg2, percentage in overlaps.items():\n",
    "        if sdg1 != sdg2:\n",
    "            print(f\"  With SDG {sdg2}: {percentage}%\")\n",
    "\n",
    "# Overlapping features\n",
    "print(\"\\nDetailed Overlapping Features:\")\n",
    "for sdg1, sdg_overlaps in overlap['overlapping_features'].items():\n",
    "    for sdg2, features in sdg_overlaps.items():\n",
    "        if features:\n",
    "            print(f\"SDG {sdg1} and SDG {sdg2} share: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luke\\anaconda3\\envs\\skmob\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luke\\anaconda3\\envs\\skmob\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luke\\anaconda3\\envs\\skmob\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luke\\anaconda3\\envs\\skmob\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luke\\anaconda3\\envs\\skmob\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luke\\anaconda3\\envs\\skmob\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "configurations = [\n",
    "    {'vectorizer': 'count', 'ngram_range': (1, 1), 'min_df': 3},\n",
    "    {'vectorizer': 'count', 'ngram_range': (2, 2), 'min_df': 3},\n",
    "    {'vectorizer': 'count', 'ngram_range': (1, 2), 'min_df': 3},\n",
    "    {'vectorizer': 'tfidf', 'ngram_range': (1, 1), 'min_df': 3},\n",
    "    {'vectorizer': 'tfidf', 'ngram_range': (2, 2), 'min_df': 3},\n",
    "    {'vectorizer': 'tfidf', 'ngram_range': (1, 2), 'min_df': 3}\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configurations:\n",
    "    vectorizer_type = config['vectorizer']\n",
    "    ngram_range = config['ngram_range']\n",
    "    min_df = config['min_df']\n",
    "    \n",
    "    run1 = sdg_classifier2(train_corpus=corpus, corpus2=corpus2, train_label=sdg_num, \n",
    "                           classifier_algorithm='multinomialnb', \n",
    "                           vectorizer_type=vectorizer_type, \n",
    "                           ngram_range=ngram_range, min_df=min_df)\n",
    "    \n",
    "    run2 = sdg_classifier2(train_corpus=corpus, corpus2=corpus2, train_label=sdg_num, \n",
    "                           classifier_algorithm='mlp', \n",
    "                           vectorizer_type=vectorizer_type, \n",
    "                           ngram_range=ngram_range, min_df=min_df)\n",
    "    \n",
    "    run3 = sdg_classifier2(train_corpus=corpus, corpus2=corpus2, train_label=sdg_num, \n",
    "                           classifier_algorithm='ridge', \n",
    "                           vectorizer_type=vectorizer_type, \n",
    "                           ngram_range=ngram_range, min_df=min_df)\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        'vectorizer': vectorizer_type,\n",
    "        'ngram_range': str(ngram_range),\n",
    "        'min_df': min_df,\n",
    "        'MultinomialNB_predicted_labels': run1,\n",
    "        'MLP_predicted_labels': run2,\n",
    "        'Ridge_predicted_labels': run3,\n",
    "    })\n",
    "\n",
    "results_df1 = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  vectorizer ngram_range  min_df MultinomialNB_predicted_labels  \\\n",
      "0      count      (1, 1)       3                 [15, 16, 4, 5]   \n",
      "1      count      (2, 2)       3                 [15, 16, 4, 3]   \n",
      "2      count      (1, 2)       3                 [15, 16, 4, 3]   \n",
      "3      tfidf      (1, 1)       3                 [15, 16, 4, 5]   \n",
      "4      tfidf      (2, 2)       3                 [15, 16, 4, 3]   \n",
      "5      tfidf      (1, 2)       3                 [15, 16, 4, 5]   \n",
      "\n",
      "  MLP_predicted_labels Ridge_predicted_labels  \n",
      "0        [15, 5, 4, 3]         [15, 16, 4, 3]  \n",
      "1       [15, 16, 4, 3]         [15, 16, 4, 3]  \n",
      "2        [15, 5, 4, 3]          [15, 5, 4, 3]  \n",
      "3        [15, 5, 4, 3]         [15, 16, 4, 3]  \n",
      "4       [15, 16, 4, 3]         [15, 16, 4, 3]  \n",
      "5       [15, 16, 4, 3]         [15, 16, 4, 3]  \n"
     ]
    }
   ],
   "source": [
    "print(results_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Assignment: Take the main text content from these pages, and feed them into your classifier and see how your model classifies them. Are the classifications reasonable? find a case where your classification is not reasonable and explain what the model does that leads to the not ideal classification.\n",
    " ------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the classifications reasonable? \n",
    "The classifications above seem generally reasonable beacuse there is only slight variation in the classifier predicted labels.\n",
    "\n",
    "Find a case where your classification is not reasonable and explain what the model does that leads to the not ideal classification:\n",
    "The Ridge classifier seems to have had a subpar classification for its ngram range(1, 2) count vectorizer. It put classified the text as sdg label 5 when most other classifiers selected sdg 16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
